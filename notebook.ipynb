{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57066346-dea3-4b54-9abf-324b8982be8b",
   "metadata": {},
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504d8a6-c30e-4bc9-bc75-a0984df7c440",
   "metadata": {},
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12716674-77f1-47f4-88eb-5557aa02a328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9846a04b-3b28-45cf-ac53-9ee25d967ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_claim(claim):\n",
    "    doc = nlp(claim)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return tokens, entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61ea98d6-156a-41e1-800e-ed90eebb7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "def search_wikipedia(query):\n",
    "    try:\n",
    "        # Get the summary from Wikipedia (first 2 sentences)\n",
    "        summary = wikipedia.summary(query, sentences=4)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Multiple options found for {query}: {e.options}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"No relevant page found on Wikipedia.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ca278b-be00-4c0f-8cd5-1f2ef04993a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f09bcc05-6a3a-4987-8771-81eeb962d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_claim(claim, evidence):\n",
    "    x = tokenizer.encode(evidence, claim, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')\n",
    "    nli_model.to(device)\n",
    "    logits = nli_model(x.to())[0]\n",
    "    \n",
    "    # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "    # \"entailment\" (2) as the probability of the label being true \n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    prob_label_is_true = probs[:,1]\n",
    "    print(prob_label_is_true)\n",
    "    return prob_label_is_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50300f70-a998-4690-ba7e-d707549260f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_claim(claim, evidence):\n",
    "    r = verify_claim(claim, evidence)\n",
    "    result = 'ENTAILMENT' if r>0.5 else 'CONTRADICTION'\n",
    "    \n",
    "    if result == 'ENTAILMENT':\n",
    "        return \"True\"\n",
    "    elif result == 'CONTRADICTION':\n",
    "        return \"False\"\n",
    "    else:\n",
    "        # If the model isn't confident (NEUTRAL), we could default to \"Unknown\"\n",
    "        return \"Could not verify the claim.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402a2b33-6100-4824-b1bc-bc18a803575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check(claim):\n",
    "    # Step 1: Preprocess the claim to extract entities\n",
    "    tokens, entities = preprocess_claim(claim)\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(f\"Entities: {entities}\")\n",
    "    \n",
    "    # Step 2: Use one of the extracted entities to search for evidence (if entities are present)\n",
    "    if entities:\n",
    "        # Take the first entity to search for on Wikipedia\n",
    "        entity_to_search = entities[0][0]\n",
    "        print(f\"Searching Wikipedia for: {entity_to_search}\")\n",
    "        \n",
    "        evidence = search_wikipedia(entity_to_search)\n",
    "        print(f\"Evidence found: {evidence}\")\n",
    "        \n",
    "        # Step 3 & 4: Fact-check and generate the response\n",
    "        response = respond_to_claim(claim, evidence)\n",
    "        print(response)\n",
    "        return response\n",
    "    else:\n",
    "        return \"Could not find any entities to search for evidence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b3400bf-5d3a-4600-9d3a-63611d31fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['friend', '9', 'seasons']\n",
      "Entities: [('Friend', 'ORG'), ('9 seasons', 'DATE')]\n",
      "Searching Wikipedia for: Friend\n",
      "Evidence found: Friends is an American television sitcom created by David Crane and Marta Kauffman, which aired on NBC from September 22, 1994, to May 6, 2004, lasting ten seasons. With an ensemble cast starring Jennifer Aniston, Courteney Cox, Lisa Kudrow, Matt LeBlanc, Matthew Perry and David Schwimmer, the show revolves around six friends in their 20s and early 30s who live in Manhattan, New York City. The original executive producers were Kevin S. Bright, Kauffman, and Crane.\n",
      "Kauffman and Crane began developing Friends under the working title Insomnia Cafe between November and December 1993.\n",
      "tensor([0.1681], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "False\n",
      "Claim: Friend had 9 seasons. -> Result: False\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # User input\n",
    "    claim = \"Friend had 9 seasons.\"\n",
    "    \n",
    "    # Check the claim\n",
    "    result = fact_check(claim)\n",
    "    print(f\"Claim: {claim} -> Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abdf073e-4b7b-4aac-83ce-085eb7662038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
